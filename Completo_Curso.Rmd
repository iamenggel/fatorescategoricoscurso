---
title: "Aula Curso R"
author: "Enggel Carmo"
date: "25/06/2021"
output: 
    html_document:
      toc: yes
      toc_float:
        collapsed: yes
        smooth_scroll: no
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE }
knitr::opts_chunk$set(echo = TRUE)
``` 
<br>

# Curso R – Guia Prático para análise de variáveis categóricas  

+ Por que eu estou aprendendo isso?
    + Lembrar da Instalação do R
    + Instalação do R Studio
    + Instalação do pacote R Markdown 
    + Abrir o R studio
    + Abrir o R markdown  
<br>

# Dia 1- Criando um documento no R Markdown

 - Será que as funções estão sendo salvas?
 - Tem que dar espaço para a palavra :)  
 - Dar **dois espaços** no fim das linhas em branco para mostrar (ao programa) que estamos pulando uma linha  (em negrito  - entre asterisco)
 - Para *itálico* (apenas um asteriscos)
 - O R^2^ está sobrescrito  (entre circunflexo)
 - O teste~12~ está subescrito  (entre til)
 - Coisas com cara de código fica `shapiro.wilk`  (entre acento grave)

 
> Link clicável abaixo 
 
[Meu linkedin:](https://www.linkedin.com/in/enggel-carmo/)

> Adicionar imagem  


![](https://entretetizei.com.br/site/wp-content/uploads/2020/12/17632380-high-res-fleabag-1-1554806597-1536x1024.jpg){ width=30% } 

### Criando referências

De acordo com Crawley 2012 [^1].  

[^1]: Crawley, M. J. (2012). The R book. John Wiley & Sons.

## Parte 1.  

### Criar pasta para o curso     
### Criar documento `RMarkdown`  
### Salvar documento `Dados_CursoR.txt` na pasta para o curso
### Salvar documento **Untitled** na pasta do curso  

### Salvar documento `.docx` > Mostrar documento salvo    

# Dia 2 - Importar dados - Distribuição Normal 

## Parte 2. Instalar pacotes 

### Instalar pacotes que serão necessários para o curso
```{r Pacotes , warning=FALSE, message=FALSE}
library (MASS)
library (car)
library(multcompView)#TukeyHSD
library(dplyr)
library(rstatix)
library(emmeans)
library(ggplot2)
library(gplots)
library(knitr) #personalização
library(kableExtra) #personalização
library(htmltools) #personalização
```

### Importar dados `Dados_CursoR.txt`

> Os formatos mais comuns para importar dados da sua máquina são .csv ou .txt

- Lembrar que .csv deve especificar que as colunas estão separadas por ;
- Anotações dentro e fora do *{r}*
```{r Dados}
dados<-read.table("Dados_CursoR.txt",h=T) #comentários > h=T quer dizer que existe um cabeçalho
dados
attach(dados) #direciona que os dados utilizados será do arquivo que estamos utilizando no momento fixando na análise
summary(dados)

nrow(dados[which(dados$Dieta=="pulgao"),]) #tamanho do nível específico

```
  
### Representação da variável **ovos**

Avaliaremos os dados de oviposição e sobrevivência da espécie *Eriopis connexa* em relação as **dietas** consumidas/ofertadas, logo são **variáveis categóricas**.  

```{r}
hist(ovos)
```  
  
###  Representação gráfica dos quantiles  

Pode auxiliar na escolha do modelo que a distribuição dos seus dados melhor se encaixa.  

```{r}
par(mfrow=c(1,2)) # plot de dois gráficos na mesma folha
qqp(ovos, "norm") #quantile quantile plot da distribuição normal
```


![](https://i.stack.imgur.com/6d3xN.jpg){ width=60% }   


## Parte 3. Análise para dados com distribuição Normal ou Gaussiana   

### Vamos testar a distribuição para a variável **ovos**  

+ Distribuição Normal ou Gaussiana  
    + Concentração de valores em torno de um valor central;
    + Simetria em torno do valor central;
    + Frequência pequena de valores muito extremos.  
    
  A distribuição normal possui dois parâmetros, a média (μ), ou seja onde está centralizada e a variância (σ2>0) que descreve o seu grau de dispersão. Ou ainda o desvio padrão (σ). Cabe salientar que como qualquer outro modelo, dependendo dos parâmetros, teremos diferentes distribuições normais.

Aceitar  
H~0~: consistem em dizer que há normalidade nos dados - p > 0.05  

H~1~: que não há - p < 0.05  

![](https://miro.medium.com/max/700/1*NRlqiZGQdsIyAu0KzP7LaQ.png){ width=60% } 

```{r}
shapiro.test(ovos)
```
  
### Vamos testar a homocedasticidade para **ovos**

Homocedasticidade é o termo para designar variância constante dos erros experimentais. *Cada nível tem sua variação em torno da média, se estes apresentam grande variação, mostra que os dados não são **homogêneos**.*

Quando *p-valor* for **menor** que o nível de significância escolhido para o teste (em geral, convencionado em 0,05), rejeita-se a H~0~ e aceitamos hipótese alternativa, assumindo a **desigualdade das variâncias**. Caso ele seja **maior** que o nível de significância, concluímos que **as variâncias são constantes ou homogêneas**.
```{r}
bartlett.test(ovos ~ Dieta, data = dados)
```
  
### Boxplot  

```{r}
boxplot(ovos~Dieta)
```


### *ANOVA*
```{r}
modelo1<-aov(ovos~Dieta)
anova(modelo1,test="F")
```
### Agora podemos fazer o teste t para separação de médias  
```{r}
Tukey<-TukeyHSD(x=modelo1,'Dieta', conf.level = 0.95)
Tukey
```
  
> Extra: Shapiro-Wilk de cada nível dentro do grupo

```{r Shapiro para cada nível, warning=FALSE, message=FALSE}
library(RVAideMemoire)
byf.shapiro(ovos~Dieta, data=dados)
```  
## Parte 4. Como representar essas informações no trabalho?

#### Nos resultados: O tipo de dieta apresentou efeito ou diferença significativa sobre a fecundidade de *Eriopis connexa* (F~2,33~19.7, P<0.001).


## Análise descritiva  {.tabset .tabset-fade}

### Médias e erros

```{r}
medias<-tapply(ovos, Dieta, mean)
medias

erro<-tapply(ovos, Dieta, sd)/sqrt(tapply(ovos, Dieta, length))
erro
```
### Representação em Barplot  

```{r}
barplot2(medias,
 plot.ci=T,
 ci.u=medias+erro,
 ci.l=medias-erro,
 ylab="Nº de ovos",
 ylim=c(0,150),
 las=1,
 names.arg = c("Cochonilha","Ovos", "Pulgão"),
 col=c("gray","lightgreen", "darkgreen"))
 text(0.7,90,"a")
 text(1.9,50,"b")
 text(3.1,110,"a")
abline(h=0)
```

Livro R markdown [^2]. 
[Livro:](https://bookdown.org/yihui/bookdown/)  

[^2]: Xie, Y. (2016). Bookdown: authoring books and technical documents with R markdown. CRC Press.


**Lembrar de fazer o `detach` para desafixar a tabela do programa.**  

**Risco de "chamar" variável de outra tabela por ter nomes idênticos.**

 **Salvar documento `.docx` > Mostrar documento salvo**
 <br>  
####Exercício: Façam o mesmo script para `larvas`.  

> Quem souber transformar para Box-Cox, log ou sqrt fique à vontade também ou ver se a distribuição se encaixa melhor para Gamma.

<br>
Vem aí:   

# Dia 3 - E quando nossos dados não apresentam distribuição normal?  

- GLM - Distribuição Poisson   
- GLM - Distribuição Binomial Negativa.   
- Análise de contraste.  

<br>

## Premissas para análises paramétricas dos dados:
- Distribuição normal;
- Variância constante 
- Independência

## Existem várias situações onde os dados não apresentam essas características 

- As respostas são binária(0,1), ou contávéis
- Apresentam distribuição não-normal [^3].

[^3]: Demétrio, C. G., Hinde, J., & Moral, R. A. (2014). Models for overdispersed data in entomology. In Ecological modelling applied to entomology (pp. 219-259). Springer, Cham.

### Soluções para esse "problema"    
#### Transformação dos dados  
- Induz aproximação para normalidade;
- Estabiliza a variância;
- **não é garantia que uma transformação irão resolver esses problemas: pode haver uma troca entre homocedasticidade e linearidade e necessidade de aplicação de outro modelo** [^4].

[^4]: St‐Pierre, A. P., Shikon, V., & Schneider, D. C. (2018). Count data in biology—Data transformation or model reformation?. Ecology and evolution, 8(6), 3077-3085.

#### Modelos lineares generalizados (GLM)

-  Os pesquisadores biológicos podem especificar diretamente a distribuição de erros e a relação entre a média e a variância;
    - Erro binomial (binário) 
    - Erro Poisson (contagens por unidade) [^5].  
    
[^5]: O'Hara, R., & Kotze, J. (2010). Do not log-transform count data. Nature Precedings, 1-1.

### GLM Gaussian  
```{r Normal/Gaussian}
gauss=glm(ovos~1)
gauss1=glm(ovos~Dieta) #modelo
anova(gauss,gauss1,test="F")
```
`gauss` é o modelo nulo (sem efeito do tratamento)  
`gauss1` é o modelo "mais completo" com efeito do tratamento = _Dieta_

Os modelos apresentaram diferença entre si, ou seja, a _Dieta_ apresentou efeito na análise  

<br>

#### *ANOVA*
```{r}
anova(gauss1,test="F")

#Podemos observar que na propria tabela já descreve que o modelo é Gaussian
```
A Análise de Deviância do `gauss1` mostrou que a _Dieta_ afetou signficativamente a fecundidade de *Eriopis connexa*.
<br>

```{r}
summary(gauss1)

#Residual deviance:  7513.6  on 42  degrees of freedom

7513.6/42
```

### Modelagem para dados contáveis que não apresentam distribuição normal  

### GLM Poisson [^6].  
[^6]: Warton, D. I., Lyons, M., Stoklosa, J., & Ives, A. R. (2016). Three points to consider when choosing a LM or GLM test for count data. Methods in Ecology and Evolution, 7(8), 882-890.

```{r Poisson}
ovi=glm(ovos~1,poisson) #modelo nulo
ovi1=glm(ovos~Dieta,poisson) #modelo completo'  
# Adicionar o tipo de distribuição no modelo
anova(ovi,ovi1,test="Chisq") #Teste qui-quadrado
```
#### *ANODEV*
```{r}
anova(ovi1,test="Chisq")
# Análise de deviância do modelo completo
```
Tabela com os dados que devem ser adicionados aos resultados  

Efeito da _Dieta_ na fecundidade (X^2^=306.39; df=2,33; *P*<0.001)  

#### Análise de resíduos

Como sabemos se os dados obedecem a distribuição Poisson?  
    - qqp (quantile-quantile plot)  
    - plot quantile  
    - "Envelope"  
    - Análise pelo resíduo da deviancia e seu grau de liberdade  
<br>  

qqp (quantile-quantile plot)
```{r}
#poisson <- fitdistr(ovos, "Poisson") # calculo do parâmetro lambda utilizado para Poisson
#poisson
#qqp(ovos, "pois", lambda=poisson$estimate)
```

Plot quantile  
```{r Plot quantile}
par(mfrow=c(2,2)) #linhas,colunas
plot(ovi1,which=c(1:4),pch=20)
```
<br>
Envelope

Precisa instalar o pacote `RT4bio`
```{r Envelope, message=FALSE, warning=FALSE}
library(RT4Bio)
rdiagnostic(ovi1)
```  

Análise de resíduo
```{r analise de residuo}
summary(ovi1)
```
Residual deviance: 183.81 on 42  degrees of freedom
```{r}
130.51/42
```
### GLM Binomial Negativa

```{r}
m0b=glm.nb(ovos~1) #binomial negativa glm.nb
m1b=glm.nb(ovos~Dieta)
anova(m0b,m1b)
```
#### *ANODEV*
```{r, message= FALSE, warning= FALSE}
anova(m1b)
```
Efeito da _Dieta_ na fecundidade (X^2^=54.078; df=2,33; *P*<0.001)  
<br>
  
#### Análise de resíduo  {.tabset .tabset-fade}    

##### plot quantile  
```{r}
par(mfrow=c(2,2))
plot(m1b,which=c(1:4),pch=20)
```

##### Envelope    
```{r}
library(RT4Bio)
rdiagnostic(m1b)
```

##### Análise do resíduo  
```{r}
summary(m1b)
```
Residual deviance: 46.244  on 42  degrees of freedom  
```{r}
48.201/42
```
Podemos aceitar a distribuição Binomial Negativa para os nossos dados, pois é onde o erro tem menor variação.
<br>  

### Análise de contraste para separação das médias    
- Vamos tentar juntas os níveis/tratamentos que tem médias mais próximas
- Criar modelos e compará-los  
        - Se existe diferença entre os modelos os níveis são diferentes;  
        - Se não há diferença entre os modelos (*P*>0.05) os tratamentos não apresentam diferença.

```{r}
Dieta= as.factor(Dieta)
medias=tapply(ovos, Dieta, mean)
medias

sort(medias)
``` 
Vamos tentar juntas os níveis/tratamentos que tem médias mais próximas
```{r}
dieta2=Dieta
dieta2
```

```{r}
levels(dieta2)[1]= "cocpug"
levels(dieta2)[3]= "cocpug"
levels(dieta2)
```
Criando modelo com os níveis _cochonilha_ e _pulgão_ amalgamados
```{r}
m2b=glm.nb(ovos~dieta2)
anova(m1b,m2b)
```
*P*= 0.11, então os modelos podem ser amalgamados;  
Cochonilhas e pulgão não apresentam diferença significativa;
<br>
Poderiamos amalgamar _Dieta_ ovos e cochonilhas ?
```{r}
dieta3=Dieta
dieta3
levels(dieta3)[1]= "ovcoc"
levels(dieta3)[2]= "ovcoc"
levels(dieta3)
m3b=glm.nb(ovos~dieta3)
anova(m1b,m3b)
```
Os modelos apresentam diferença significativa, não podemos amalgamálos.

Logo, podemos definir que temos as letras  
- Pulgão **a**  
- Cochonilha **a**  
- Ovos **b**  

### Gráfico _Boxplot_    
```{r}
boxplot(ovos~Dieta,
 ylab="Nº de ovos",
 ylim=c(0,150),
 las=1,
 names.arg = c("Cochonilha","Ovos", "Pulgão"),
 col=c("gray","lightgreen", "darkgreen"))
 text(0.7,100,"a")
 text(1.7,50,"b")
 text(2.7,112,"a")
```
<br>  

#### Lembrar de fazer o `detach` para desafixar a tabela do programa  

Risco de "chamar" variável de outra tabela por ter nomes identicos  

```{r}
detach(dados)
```

Salvar documento `.docx` > Mostrar documento salvo  

<br>
<br>

# Dia 4 - Porcentagem/ Presença e ausência.   

- GLM Binomial – Fertilidade + Análise de contraste 
- GLM Binomial - Sobrevivência [^7].

[^7]: Se houver tempo. 

<br>   

### GLM Binomial 

### Carregar os dados
```{r}
dados<-read.table("Dados_CursoR.txt",h=T)
attach(dados)
head(dados)
```


### Construção dos modelos   
- (parcial/total)  
- wights = total  
- família binomial  

```{r}
mb0=glm(larvas/ovos~1,weights = ovos,binomial) #modelo nulo, aleatório
mb1=glm(larvas/ovos~Dieta,weights = ovos,binomial) #modelo completo, com efeito do tratament (Dieta)
anova(mb0,mb1,test="Chisq")
```


Análise de deviancia
```{r}
anova(mb1,test="Chisq") #tabela da ANOVA
```


Teste de sobredispersão
- (Envelope)
```{r}
par(mfrow=c(2,2))
plot(mb1,which=c(1:4),pch=20)
rdiagnostic(mb1)
```


Informações para o texto dos resultados
```{r}
summary(mb1)
```

```{r}
102.61/42
```

### Binomial Negativa  

Correção
```{r binomial negativa, warning=FALSE}
help0=glm.nb((larvas/ovos)*100~1) #binomial negativa glm.nb
help1=glm.nb((larvas/ovos)*100~Dieta)
anova(help0,help1)
```


Análise de deviancia
```{r, warning= FALSE}
anova(help1)
```

Análise de dispersão
```{r}
par(mfrow=c(2,2))
plot(help1,which=c(1:4),pch=20)
rdiagnostic(help1)
```
```{r}
summary(help1)
```


### Análise de residuos  
Residual deviance:  80.824  on 42  degrees of freedom
```{r}
80.824/42
```

### Análise descritiva dos dados

```{r}
media<-tapply((larvas/ovos)*100,Dieta,mean)
media

erro<-tapply((larvas/ovos)*100,Dieta, sd)/sqrt(tapply((larvas/ovos)*100,Dieta, length))
erro
```

```{r}
barplot2(media,
 plot.ci=T,
 ci.u=media+erro,
 ci.l=media-erro,
 ylim=c(0,100),
 ylab="Fertilidade (%)",
  names.arg = c("Cochonilha","Ovos", "Pulgão"),
 col=c("gray","lightgreen", "darkgreen"),
 las=1
 )
abline(h=0)
```


### Dados Binomiais de Presença e ausência (0 ou 1)  
<br>
Análise binomial não é a mais recomendada para análise de sobrevivência. Esta é uma característica (mortalidade) que é avaliada e acompanhada ao longo do tempo e são utilizadas outras ferramentas/distribuições (Weibull e Kruskal-Wallis). 
<br>
Então a pergunta aqui é:  
Qual a taxa de sobrevivência no final dos dias de observação?
<br>  
Contrução do modelo para observação do efeito do tratamento  
```{r}
m0=glm(censor/total~1,weights = total,binomial)
pre1=glm(censor/total~Dieta,weights = total,binomial) #modelo
anova(m0,pre1,test="Chisq")
```

Análise de deviancia do modelo com efeito do tratamento
```{r}
anova(pre1,test="Chisq")
```


Análise de sobredispersão
```{r}
par(mfrow=c(2,2))
plot(pre1,which=c(1:4),pch=20)
rdiagnostic(pre1)
```

Apresentação dos dados para os resultados
```{r}
summary(pre1)
```


### Análise de resíduos   

Residual deviance: 49.905  on 42  degrees of freedom
```{r}
49.905/42
```

### Representação gráfica  


```{r}
plot((censor/total)~survive,
 las=1,
 ylab = "Sobrevivência",
 xlim=c(0, 3.0),
 bty= "n")

curve(exp(1.8718-0.7596*x)/(1+exp(1.8718-0.7596*x)), #curva de alto recurso
 add=T,
 lwd=2, #espessura da reta (aumenta o valor = aumenta a espessura)
 lty=4, #estilo da reta (1=contínuo; 2=tracejado)
 col="green")

curve(exp(1.8718-2.8834*x)/(1+exp(1.8718-2.8834*x)), #curva de alto recurso
 add=T,
 lwd=1, #espessura da reta (aumenta o valor = aumenta a espessura)
 lty=1, #estilo da reta (1=contínuo; 2=tracejado)
 col="black")

curve(exp(1.8718-2.8834*x -1.7383 )/(1+exp(1.8718-2.8834*x -1.7383 )), #curva baixo recurso
 add=T,
 lwd=1, #espessura da reta (aumenta o valor = aumenta a espessura)
 lty=2, #estilo da reta (1=contínuo; 2=tracejado)
 col="black")

legend("topleft", #posição da legenda
 c("Pulgão","Cochonilhas", "Ovos"), #informa os fatores
 lty = c(1, 2), #informa as linhas
 col=c("green", "black","black"), #informa a coloração
 bty = "n")
text(1060,0.2,"P < 0.001",font=3)
```
### Análise descritiva  

```{r}
media2=tapply(censor/total,Dieta, mean)
media2

erro2=tapply(censor/total,Dieta, sd)/sqrt(tapply(censor/total,Dieta,
length))
erro2
```
### Gráfico  
```{r, message= FALSE, warning=FALSE}
#install.packages("RColorBrewer")
library(RColorBrewer)

cores <- brewer.pal(3, "Dark2")

cores2 <- brewer.pal(3, "Paired")
cores3 <- brewer.pal(10, "Set2")

library(ggplot2)
barplot2(media2,col=cores2,
 plot.ci=T,
 ci.u=media2+erro2,
 ci.l=media2-erro2,
 ylim=c(0.0,1.0),
 las=1,
 ylab="% Fêmeas vivas",
 names.arg = c("Cochonilhas","Ovos", "Pulgão"),
 )
abline(h=0)
```
Trabalhar com cores no R [^8].  

[^8]: https://diegonogare.net/2015/09/trabalhar-com-cores-no-r/

```{r}
a <- c(1:10)
color <- colorRampPalette(c("red","yellow", "green"))
color(10)
barplot(a, col=color(10))
abline(h=0)
```
```{r}
b <- c(1:10)
corDegrade <- colorRampPalette(c("green","darkblue")) # Degradê de verde para azul
corDegrade(10)
barplot(b, col=corDegrade(10))
abline(h=0)
```

```{r}
detach (dados)
```


